{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UznetDev/Data-science-home-work/blob/main/MNIST_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qEDsU3eL95t",
        "outputId": "4fc2dd2e-8326-409f-ca0b-f06572b18091"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 18 12:12:30 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lKOcU7dPL_zM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XRlEJXWMEnY",
        "outputId": "ebb02f94-7a08-45f1-ea5d-bc18e2f11ea2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std deviation of MNIST\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28 * 28, 100)  # First hidden layer with 100 nodes\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(100, 50)  # Second hidden layer with 50 nodes\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.output = nn.Linear(50, 10)  # Output layer for 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.output(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL78eBHUMJsZ",
        "outputId": "0e46307f-3c46-4f3a-8b16-660eb5f80e00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 504kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.55MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and move the model to the appropriate device\n",
        "model = MLP().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7mwRKpkMRYm",
        "outputId": "1a2fb430-3c5b-4987-dc93-2756c542e694"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7829\n",
            "Epoch [2/10], Loss: 0.2884\n",
            "Epoch [3/10], Loss: 0.2286\n",
            "Epoch [4/10], Loss: 0.1871\n",
            "Epoch [5/10], Loss: 0.1581\n",
            "Epoch [6/10], Loss: 0.1366\n",
            "Epoch [7/10], Loss: 0.1193\n",
            "Epoch [8/10], Loss: 0.1057\n",
            "Epoch [9/10], Loss: 0.0960\n",
            "Epoch [10/10], Loss: 0.0858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy on the test set: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7AAuucWNCNf",
        "outputId": "9fbc2bd7-2378-44fe-afec-283f7ea0265b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 97.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get an iterator for the test_loader\n",
        "examples = iter(test_loader)\n",
        "\n",
        "# Get the next batch of data and labels\n",
        "example_data, example_labels = next(examples)\n",
        "\n",
        "# Perform prediction\n",
        "with torch.no_grad():\n",
        "    output = model(example_data.to(device))\n",
        "    _, pred_label = torch.max(output, 1)\n",
        "\n",
        "# Visualize the first image and its predicted label\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(example_data[0].squeeze().cpu(), cmap='gray')  # Use .cpu() if needed\n",
        "plt.title(f'Predicted Label: {pred_label[0].item()}')\n",
        "plt.axis('off')  # Hide axes for better visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "xys4H5V4KKkg",
        "outputId": "f0589f64-eae2-466f-b9ba-f5c9f55cad15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#update and save model"
      ],
      "metadata": {
        "id": "cgYk0gihFB6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std deviation of MNIST\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28 * 28, 100)  # First hidden layer with 100 nodes\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(100, 50)  # Second hidden layer with 50 nodes\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.output = nn.Linear(50, 10)  # Output layer for 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate and move the model to the appropriate device\n",
        "model = MLP().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
        "\n",
        "# Save the trained model to a joblib file\n",
        "torch.save(model.state_dict(), 'mnist_mlp.pth')\n",
        "joblib.dump(model, 'mnist_mlp.joblib')\n",
        "\n",
        "print(\"Model has been saved as 'mnist_mlp.pth' and 'mnist_mlp.joblib'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUWZ3E9XZZzq",
        "outputId": "7ad735f0-a592-4bbe-b030-e10886c687ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.57MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.84MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch [1/10], Loss: 0.8029\n",
            "Epoch [2/10], Loss: 0.2776\n",
            "Epoch [3/10], Loss: 0.2202\n",
            "Epoch [4/10], Loss: 0.1804\n",
            "Epoch [5/10], Loss: 0.1531\n",
            "Epoch [6/10], Loss: 0.1320\n",
            "Epoch [7/10], Loss: 0.1168\n",
            "Epoch [8/10], Loss: 0.1021\n",
            "Epoch [9/10], Loss: 0.0925\n",
            "Epoch [10/10], Loss: 0.0826\n",
            "Model has been saved as 'mnist_mlp.pth' and 'mnist_mlp.joblib'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import joblib\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Load the saved model\n",
        "model = MLP()\n",
        "model.load_state_dict(torch.load('mnist_mlp.pth'))\n",
        "model.to(device)  # Move model to the appropriate device\n",
        "model.eval()\n",
        "\n",
        "# Function to predict handwritten digit from an external image path\n",
        "def predict_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(),  # Ensure the image is grayscale\n",
        "        transforms.Resize((28, 28)),  # Resize image to 28x28\n",
        "        transforms.ToTensor(),  # Convert to tensor\n",
        "        transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std dev of MNIST\n",
        "    ])\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    image = Image.open(image_path).convert('L')  # Convert image to grayscale if not already\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Move image tensor to the same device as the model\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        return predicted.item()\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/SEVEN.jpg'  # Replace with your image path\n",
        "predicted_class = predict_image(image_path)\n",
        "print(f'Predicted class for the input image is: {predicted_class}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NVkOLNPZ60C",
        "outputId": "a38dab76-ed7e-49c1-d142-7a94898caa56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class for the input image is: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-281f36bd95e0>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('mnist_mlp.pth'))\n"
          ]
        }
      ]
    }
  ]
}